[default]
data_path = DBTT_Data20_0meanNorm.csv
#save_path = graphs/{}.png
save_path = tasks/saved/graphs/{}.png
lwr_data_path = CD_LWR_clean8_0meanNorm.csv
X = N(Cu),N(Ni),N(Mn),N(P),N(Si),N( C ),N(Temp),N_log(eff fl p =.1),N_log(eff fl p =.2),N_log(eff fl p =.3)

Y = N_std_delta sigma
#Y = N_std_CD delta sigma

#The name of the program that creates the model, there should be a get() function in this file which returns the model
model = gkrr_model
test_cases = ErrorBias,DescriptorImportance,KFold_CV,LeaveOutAlloyCV,FullFit,FluenceFluxExtrapolation

#The configuration for AllTests.py
[AllTests]
data_path = ${default:data_path}
save_path = ${default:save_path}
lwr_data_path = ${default:lwr_data_path}
X = ${default:X}
Y = ${default:Y}
model = gkrr_model
weights = False

#list of all the tests you need, name should be exactly same as the file name.
#The execute() function of each file will be called
#test_cases = ${default:test_cases}
test_cases = ExtrapolateToLWR

#if some test files have different configuration setting than AllTests, you can make changes by adding a
#separate section

[ExtrapolateToLWR]
#experimental
sigma = 66.1348995033
mean = 80.1519721578
#CD
# sigma = 60.4428505113
# mean =  55.3370401856

[gkrr_model]
#responseNormalized = 0mean1sigma
#experimental
alpha = 0.006158482
gamma = 1.199353946
#CD
#alpha = 0.002976351
#gamma = 1.199353946

coef0 = 1
degree = 3
kernel = rbf

[dtr_model]
max_depth = 5
min_samples_split = 2
min_samples_leaf = 1
split criterion = mse

[lkrr_model]
alpha = 0.00518
gamma = 0.518
kernel = laplacian

[randomforest_model]
estimators = 100
max_depth = 5
min_samples_split = 2
min_samples_leaf = 1
max_leaf_nodes = None
jobs = 1

[adaboost_model]
estimators = 275
max_depth = 12
min_samples_split = 2
min_samples_leaf = 1
learning rate = 1
loss function = linear

#minmax, size, transfer_function are the verbatim arguments for neurolab.net.newff()
#training_algorithm is the verbatim 'support train fcn' for neurolab.train omitting 'train_'
#see: https://pythonhosted.org/neurolab/lib.html#module-neurolab.net
#epochs,show,goal are neurolab.net.train() arguments
#see: https://pythonhosted.org/neurolab/lib.html#train-algorithms-based-gradients-algorithms
#NOTE: minmax is verbose b/c [[0,1]]*9 will have bad pointers
[nn_model]
minmax = [[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]]
size = [11,1]
transfer_function = TanSig
training_algorithm = bfgs
epochs = 5
show = False
goal = 0.01